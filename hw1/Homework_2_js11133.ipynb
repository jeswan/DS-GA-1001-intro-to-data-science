{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Jesse Swanson\n",
    "\n",
    "Student Netid: js11133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (5 Points)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Target's problem of identifying pregnant women as early as possible, we need to collect data on each consumer. This data must be connected to some unique user ID in order for the users to be directly targeted by marketing techniques. The data collected likely contain numerous features such where you live, estimated salary, recent purchases, etc.. The goal of a predictive modeling problem is to use the features of the data to classify consumers as pregnant or not pregnant. This is a supervised learning problem. Therefore, each vector we collect must contain information about if the consumer is preganant or an early mother. This can likely be inferred by purchasing habits such as buying diapers, baby clothes, etc.. Once we know a consumer is a mother, we can look back in their history and attempt to identify features in their vector that correlate with being a pregnant woman.\n",
    "\n",
    "After collecting a data set of consumers that are both pregnant and not pregnant, we need to train a model on the data. We are trying to select a model for a classification problem since we want to answer the question: \"Is this user pregnant?\" There are many different types of models to choose from such as decision trees, linear classifiers, support vector machines. It is best to start with a simple model such as a decision tree and build complexity as needed. Simple models are often more transparent and easier for audiences to grasp. For a model like the decision tree, we will iterate through each of the features of the data set to determine which feature gives the most information gain. Features with the most information gain will be used to split the data first to maximize classification efficiency and reduce overfitting. After training the model on the data set, it is important to test the model on holdout data in order to check if we overfitted the model. Overfitting the model results in a higher than realistic accuracy for the model. This is because the model is too targeted towards the training data and does not generalize.\n",
    "\n",
    "Once this model is released to production, we will need the ability to retrain the model based on feedback data. Concept drift causes our model to be less accurate over time due to unforseen changes in the underlying data. For example, a pregnant mother in the 1930s likely had different purchasing behaviours than a modern mother. A model trained on a 1930s mother would likely not be accurate for a modern mother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (4 Points - 1 each)\n",
    "For this part we will be using the data file located in `\"advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell in your terminal and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work. Also, these are standard data exploration commands that are quick and easy to use in a terminal or in the notebook. We don't cover command line operations formally in this class, but these are worth learning (and thus are part of the HW). Be resourceful. Use whatever online cheat sheets or Stackoverflow to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file (look up wc)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"advertising_events.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f 1 -d , advertising_events.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google.com\r\n",
      "facebook.com\r\n",
      "youtube.com\r\n",
      "yahoo.com\r\n",
      "baidu.com\r\n",
      "wikipedia.org\r\n",
      "amazon.com\r\n",
      "qq.com\r\n",
      "twitter.com\r\n",
      "taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "!sort advertising_events.csv | uniq | sort -t , -k3 -k1 | cut -d , -f 3 | uniq -c | sort -r | awk '{$1=$1}1' |cut -d ' ' -f 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"^37,\" advertising_events.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (16 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = pd.read_csv('ads_dataset.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    d_num_nan = input_data.isna().sum().to_frame(name='number_nan')\n",
    "    d_num_dist = input_data.nunique().to_frame(name='number_distinct')\n",
    "    d_desc = input_data.describe().T\n",
    "    del d_desc['count']\n",
    "    frames = [d_number_nan, d_num_dist]\n",
    "    output_data = d_num_nan.join(d_num_dist).join(d_desc)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.3 ms ± 886 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isbuyer</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_freq</td>\n",
       "      <td>52257</td>\n",
       "      <td>10</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>visit_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.852777</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_interval</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>0.210008</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sv_interval</td>\n",
       "      <td>0</td>\n",
       "      <td>5886</td>\n",
       "      <td>5.825610</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>184.91670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>-0.198040</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.28571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>15135</td>\n",
       "      <td>-10.210786</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uniq_urls</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>86.569343</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_checkins</td>\n",
       "      <td>0</td>\n",
       "      <td>4628</td>\n",
       "      <td>720.657592</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>y_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number_nan  number_distinct        mean          std  \\\n",
       "isbuyer                       0                2    0.042632     0.202027   \n",
       "buy_freq                  52257               10    1.240653     0.782228   \n",
       "visit_freq                    0               64    1.852777     2.921820   \n",
       "buy_interval                  0              295    0.210008     3.922016   \n",
       "sv_interval                   0             5886    5.825610    17.595442   \n",
       "expected_time_buy             0              348   -0.198040     4.997792   \n",
       "expected_time_visit           0            15135  -10.210786    31.879722   \n",
       "last_buy                      0              189   64.729335    53.476658   \n",
       "last_visit                    0              189   64.729335    53.476658   \n",
       "multiple_buy                  0                2    0.006357     0.079479   \n",
       "multiple_visit                0                2    0.277444     0.447742   \n",
       "uniq_urls                     0              207   86.569343    61.969765   \n",
       "num_checkins                  0             4628  720.657592  1275.727306   \n",
       "y_buy                         0                2    0.004635     0.067924   \n",
       "\n",
       "                          min    25%    50%         75%          max  \n",
       "isbuyer                0.0000    0.0    0.0    0.000000      1.00000  \n",
       "buy_freq               1.0000    1.0    1.0    1.000000     15.00000  \n",
       "visit_freq             0.0000    1.0    1.0    2.000000     84.00000  \n",
       "buy_interval           0.0000    0.0    0.0    0.000000    174.62500  \n",
       "sv_interval            0.0000    0.0    0.0    0.104167    184.91670  \n",
       "expected_time_buy   -181.9238    0.0    0.0    0.000000     84.28571  \n",
       "expected_time_visit -187.6156    0.0    0.0    0.000000     91.40192  \n",
       "last_buy               0.0000   18.0   51.0  105.000000    188.00000  \n",
       "last_visit             0.0000   18.0   51.0  105.000000    188.00000  \n",
       "multiple_buy           0.0000    0.0    0.0    0.000000      1.00000  \n",
       "multiple_visit         0.0000    0.0    0.0    1.000000      1.00000  \n",
       "uniq_urls             -1.0000   30.0   75.0  155.000000    206.00000  \n",
       "num_checkins           1.0000  127.0  319.0  802.000000  37091.00000  \n",
       "y_buy                  0.0000    0.0    0.0    0.000000      1.00000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#buy_freq contains NaN values\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isbuyer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_freq</td>\n",
       "      <td>52257</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>visit_freq</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_interval</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sv_interval</td>\n",
       "      <td>0</td>\n",
       "      <td>5112</td>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>13351</td>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_visit</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uniq_urls</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_checkins</td>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>y_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number_nan  number_distinct        mean          std  \\\n",
       "isbuyer                       0                1    0.000000     0.000000   \n",
       "buy_freq                  52257                0         NaN          NaN   \n",
       "visit_freq                    0               48    1.651549     2.147955   \n",
       "buy_interval                  0                1    0.000000     0.000000   \n",
       "sv_interval                   0             5112    5.686388    17.623555   \n",
       "expected_time_buy             0                1    0.000000     0.000000   \n",
       "expected_time_visit           0            13351   -9.669298    31.239030   \n",
       "last_buy                      0              189   65.741317    53.484622   \n",
       "last_visit                    0              189   65.741317    53.484622   \n",
       "multiple_buy                  0                1    0.000000     0.000000   \n",
       "multiple_visit                0                2    0.255602     0.436203   \n",
       "uniq_urls                     0              207   86.656180    61.996711   \n",
       "num_checkins                  0             4570  721.848518  1284.504018   \n",
       "y_buy                         0                2    0.003024     0.054904   \n",
       "\n",
       "                          min    25%    50%         75%          max  \n",
       "isbuyer                0.0000    0.0    0.0    0.000000      0.00000  \n",
       "buy_freq                  NaN    NaN    NaN         NaN          NaN  \n",
       "visit_freq             1.0000    1.0    1.0    2.000000     84.00000  \n",
       "buy_interval           0.0000    0.0    0.0    0.000000      0.00000  \n",
       "sv_interval            0.0000    0.0    0.0    0.041667    184.91670  \n",
       "expected_time_buy      0.0000    0.0    0.0    0.000000      0.00000  \n",
       "expected_time_visit -187.6156    0.0    0.0    0.000000     91.40192  \n",
       "last_buy               0.0000   19.0   52.0  106.000000    188.00000  \n",
       "last_visit             0.0000   19.0   52.0  106.000000    188.00000  \n",
       "multiple_buy           0.0000    0.0    0.0    0.000000      0.00000  \n",
       "multiple_visit         0.0000    0.0    0.0    1.000000      1.00000  \n",
       "uniq_urls             -1.0000   30.0   75.0  155.000000    206.00000  \n",
       "num_checkins           1.0000  126.0  318.0  803.000000  37091.00000  \n",
       "y_buy                  0.0000    0.0    0.0    0.000000      1.00000  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = ads[pd.isnull(ads['buy_freq'])]\n",
    "getDfSummary(df1)\n",
    "# isbuyer, buy interval, expected_time_buy, multiple_buy correlate with the missing buy_freq entries. Since all of\n",
    "# the correlated variables are 0 when buy_freq = NaN, it is likely that the missing buy_freq should be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isbuyer, multiple_buy, multiple_visit, y_buy since they only have 2 distinct values"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
